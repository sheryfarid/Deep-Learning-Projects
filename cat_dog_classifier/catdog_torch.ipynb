{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOm1nux2NEDCCfRNvid25HC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"LvKczulSrscZ","executionInfo":{"status":"ok","timestamp":1751126359237,"user_tz":-300,"elapsed":7664,"user":{"displayName":"28 Shehryar Ahmed","userId":"00947876017490583777"}}},"outputs":[],"source":["!pip install -q kaggle\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json"]},{"cell_type":"code","source":["!kaggle datasets download -d salader/dogs-vs-cats\n","!unzip -q dogs-vs-cats.zip -d dogs_vs_cats_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XevG8Za1sQ9Y","executionInfo":{"status":"ok","timestamp":1751126389315,"user_tz":-300,"elapsed":30065,"user":{"displayName":"28 Shehryar Ahmed","userId":"00947876017490583777"}},"outputId":"d134a9c2-35d6-4492-aa43-227302b6e160"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset URL: https://www.kaggle.com/datasets/salader/dogs-vs-cats\n","License(s): unknown\n","Downloading dogs-vs-cats.zip to /content\n"," 98% 1.04G/1.06G [00:08<00:00, 178MB/s]\n","100% 1.06G/1.06G [00:08<00:00, 136MB/s]\n"]}]},{"cell_type":"code","source":["from torchvision.datasets import CIFAR10\n","from torchvision.utils import save_image\n","from torchvision import transforms\n","import os\n","os.makedirs(\"/content/dogs_vs_cats_data/train/other\", exist_ok=True)\n","os.makedirs(\"/content/dogs_vs_cats_data/test/other\", exist_ok=True)\n","\n","from torchvision.datasets import CIFAR10\n","from torchvision.utils import save_image\n","\n","# Load CIFAR10\n","cifar = CIFAR10(root=\"./\", train=True, download=True)\n","\n","# Save 200 'other' images (excluding cat=3, dog=5)\n","count = 0\n","for i, (img, label) in enumerate(cifar):\n","    if label not in [3, 5]:  # Skip cat(3) and dog(5)\n","        save_image(transforms.ToTensor()(img), f\"/content/dogs_vs_cats_data/train/other/img_{count}.jpg\")\n","        count += 1\n","    if count >= 200:\n","        break\n","\n","\n","# Load CIFAR10 test set\n","cifar_test = CIFAR10(root=\"./\", train=False, download=True)\n","\n","# Save 100 'other' images to test set\n","count = 0\n","for i, (img, label) in enumerate(cifar_test):\n","    if label not in [3, 5]:  # skip cat (3) and dog (5)\n","        save_path = f\"/content/dogs_vs_cats_data/test/other/other_{count}.jpg\"\n","        save_image(transforms.ToTensor()(img), save_path)\n","        count += 1\n","    if count >= 100:\n","        break"],"metadata":{"id":"i3MohobEQbM0","executionInfo":{"status":"ok","timestamp":1751126498044,"user_tz":-300,"elapsed":7447,"user":{"displayName":"28 Shehryar Ahmed","userId":"00947876017490583777"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","import torchvision\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","\n","from torch.utils.data import DataLoader\n","import torchvision.models as models\n","from tqdm import tqdm\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using:\", device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NlVDzvbdshfE","executionInfo":{"status":"ok","timestamp":1751126553305,"user_tz":-300,"elapsed":75,"user":{"displayName":"28 Shehryar Ahmed","userId":"00947876017490583777"}},"outputId":"021865ef-9e32-4bbd-9645-5c8bd95e6ea4"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Using: cuda\n"]}]},{"cell_type":"code","source":["transform = transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5]*3, [0.5]*3)\n","])\n","\n","train_dir = \"/content/dogs_vs_cats_data/train\"\n","test_dir = \"/content/dogs_vs_cats_data/test\"\n","\n","train_ds = datasets.ImageFolder(train_dir, transform=transform)\n","val_ds = datasets.ImageFolder(test_dir, transform=transform)\n","\n","train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)"],"metadata":{"id":"ShlfjSTks8rW","executionInfo":{"status":"ok","timestamp":1751126570232,"user_tz":-300,"elapsed":100,"user":{"displayName":"28 Shehryar Ahmed","userId":"00947876017490583777"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.net = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=3, padding=1), nn.ReLU(),\n","            nn.BatchNorm2d(32), nn.MaxPool2d(2), nn.Dropout(0.25),\n","\n","            nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(),\n","            nn.BatchNorm2d(64), nn.MaxPool2d(2), nn.Dropout(0.25),\n","\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(),\n","            nn.BatchNorm2d(128), nn.MaxPool2d(2), nn.Dropout(0.25),\n","\n","            nn.Flatten(),\n","            nn.Linear(128 * 16 * 16, 128), nn.ReLU(), nn.Dropout(0.5),\n","            nn.Linear(128, 64), nn.ReLU(),\n","            nn.Linear(64, 3)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)"],"metadata":{"id":"lDwX3UjPtW5B","executionInfo":{"status":"ok","timestamp":1751126754614,"user_tz":-300,"elapsed":74,"user":{"displayName":"28 Shehryar Ahmed","userId":"00947876017490583777"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["model = CNN().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n"],"metadata":{"id":"qb9qyaeRtayq","executionInfo":{"status":"ok","timestamp":1751126861197,"user_tz":-300,"elapsed":212,"user":{"displayName":"28 Shehryar Ahmed","userId":"00947876017490583777"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["epochs = 20\n","best_val_loss = float('inf')\n","patience = 3\n","counter = 0\n","\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0\n","    correct_train = 0\n","    total_train = 0\n","\n","    for images, labels in tqdm(train_loader):\n","        images, labels = images.to(device), labels.to(device)\n","\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","\n","        # Train accuracy\n","        _, preds = torch.max(outputs, 1)\n","        correct_train += (preds == labels).sum().item()\n","        total_train += labels.size(0)\n","\n","    train_loss = total_loss / len(train_loader)\n","    train_acc = correct_train / total_train\n","\n","    # Validation\n","    model.eval()\n","    val_loss = 0\n","    correct_val = 0\n","    total_val = 0\n","\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            val_loss += criterion(outputs, labels).item()\n","\n","            _, preds = torch.max(outputs, 1)\n","            correct_val += (preds == labels).sum().item()\n","            total_val += labels.size(0)\n","\n","    val_loss /= len(val_loader)\n","    val_acc = correct_val / total_val\n","\n","    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n","    print(f\"Train     -> Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n","    print(f\"Validation-> Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        torch.save(model.state_dict(), \"cat_dog_other.pth\")\n","        print(\"‚úîÔ∏è Model improved and saved.\")\n","        counter = 0\n","    else:\n","        counter += 1\n","        print(f\"‚ö†Ô∏è No improvement. Early stop counter: {counter}/{patience}\")\n","        if counter >= patience:\n","            print(\"‚õî Early stopping.\")\n","            break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x17qIZAMtfl6","executionInfo":{"status":"ok","timestamp":1751127787028,"user_tz":-300,"elapsed":924523,"user":{"displayName":"28 Shehryar Ahmed","userId":"00947876017490583777"}},"outputId":"c842bc37-5c7e-4865-f370-25ccc30cefe2"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 632/632 [01:10<00:00,  8.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1/20\n","Train     -> Loss: 0.7591, Accuracy: 0.6130\n","Validation-> Loss: 0.6447, Accuracy: 0.6825\n","‚úîÔ∏è Model improved and saved.\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 632/632 [01:12<00:00,  8.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 2/20\n","Train     -> Loss: 0.5794, Accuracy: 0.7135\n","Validation-> Loss: 0.5286, Accuracy: 0.7625\n","‚úîÔ∏è Model improved and saved.\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 632/632 [01:10<00:00,  8.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 3/20\n","Train     -> Loss: 0.4856, Accuracy: 0.7779\n","Validation-> Loss: 0.4483, Accuracy: 0.7969\n","‚úîÔ∏è Model improved and saved.\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 632/632 [01:10<00:00,  9.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 4/20\n","Train     -> Loss: 0.4076, Accuracy: 0.8222\n","Validation-> Loss: 0.3895, Accuracy: 0.8292\n","‚úîÔ∏è Model improved and saved.\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 632/632 [01:09<00:00,  9.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 5/20\n","Train     -> Loss: 0.3511, Accuracy: 0.8480\n","Validation-> Loss: 0.3597, Accuracy: 0.8461\n","‚úîÔ∏è Model improved and saved.\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 632/632 [01:09<00:00,  9.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 6/20\n","Train     -> Loss: 0.3057, Accuracy: 0.8705\n","Validation-> Loss: 0.3251, Accuracy: 0.8618\n","‚úîÔ∏è Model improved and saved.\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 632/632 [01:09<00:00,  9.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 7/20\n","Train     -> Loss: 0.2631, Accuracy: 0.8922\n","Validation-> Loss: 0.3442, Accuracy: 0.8518\n","‚ö†Ô∏è No improvement. Early stop counter: 1/3\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 632/632 [01:09<00:00,  9.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 8/20\n","Train     -> Loss: 0.2294, Accuracy: 0.9072\n","Validation-> Loss: 0.2948, Accuracy: 0.8776\n","‚úîÔ∏è Model improved and saved.\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 632/632 [01:09<00:00,  9.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 9/20\n","Train     -> Loss: 0.1930, Accuracy: 0.9208\n","Validation-> Loss: 0.3322, Accuracy: 0.8682\n","‚ö†Ô∏è No improvement. Early stop counter: 1/3\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 632/632 [01:10<00:00,  9.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 10/20\n","Train     -> Loss: 0.1679, Accuracy: 0.9351\n","Validation-> Loss: 0.3691, Accuracy: 0.8704\n","‚ö†Ô∏è No improvement. Early stop counter: 2/3\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 632/632 [01:09<00:00,  9.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 11/20\n","Train     -> Loss: 0.1633, Accuracy: 0.9386\n","Validation-> Loss: 0.3847, Accuracy: 0.8586\n","‚ö†Ô∏è No improvement. Early stop counter: 3/3\n","‚õî Early stopping.\n"]}]},{"cell_type":"code","source":["\n","def count_images_in_folder(folder):\n","    total = 0\n","    class_counts = {}\n","    for class_name in os.listdir(folder):\n","        class_path = os.path.join(folder, class_name)\n","        if os.path.isdir(class_path):\n","            count = len([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n","            class_counts[class_name] = count\n","            total += count\n","    return total, class_counts\n","\n","# Count for train\n","train_total, train_classes = count_images_in_folder(train_dir)\n","print(f\"\\nüìÇ Train Total Images: {train_total}\")\n","for label, count in train_classes.items():\n","    print(f\"  ‚îî‚îÄ‚îÄ {label}: {count}\")\n","\n","# Count for test\n","test_total, test_classes = count_images_in_folder(test_dir)\n","print(f\"\\nüìÇ Test Total Images: {test_total}\")\n","for label, count in test_classes.items():\n","    print(f\"  ‚îî‚îÄ‚îÄ {label}: {count}\")"],"metadata":{"id":"v2M3utw9tj0W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751126580200,"user_tz":-300,"elapsed":29,"user":{"displayName":"28 Shehryar Ahmed","userId":"00947876017490583777"}},"outputId":"ba33f1a0-d7ff-43ae-d26d-84a6183d44bb"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üìÇ Train Total Images: 20200\n","  ‚îî‚îÄ‚îÄ other: 200\n","  ‚îî‚îÄ‚îÄ cats: 10000\n","  ‚îî‚îÄ‚îÄ dogs: 10000\n","\n","üìÇ Test Total Images: 5100\n","  ‚îî‚îÄ‚îÄ other: 100\n","  ‚îî‚îÄ‚îÄ cats: 2500\n","  ‚îî‚îÄ‚îÄ dogs: 2500\n"]}]},{"cell_type":"code","source":["print(\"Classes:\", train_ds.classes)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x16eshJi_aEp","executionInfo":{"status":"ok","timestamp":1751126640050,"user_tz":-300,"elapsed":55,"user":{"displayName":"28 Shehryar Ahmed","userId":"00947876017490583777"}},"outputId":"5d3f4cb4-8bad-430e-bfa1-725ed996aab3"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Classes: ['cats', 'dogs', 'other']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"4QBi80O2SAOA"},"execution_count":null,"outputs":[]}]}